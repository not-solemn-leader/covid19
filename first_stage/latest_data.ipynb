{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"latest_data.ipynb","provenance":[],"collapsed_sections":["474eFhZp0RwX","tcdZe0KZKLuI","sFM53SQ6LYAK"],"authorship_tag":"ABX9TyNGThcUaUh5D8BAK2oDswxD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OCZmeZLxCNrO","colab_type":"text"},"source":["# Ideas:\n","- Добавить данные о карантине\n","- Доавить данные о карантине и принятых мерах\n","- Добавить данные о перелетах\n","- Добавить данные по завозу тестов в страну"]},{"cell_type":"markdown","metadata":{"id":"RUR7k9Z9I0HV","colab_type":"text"},"source":["Used datasets:\n","- https://www.kaggle.com/fernandol/countries-of-the-world\n","- https://www.kaggle.com/theworldbank/world-development-indicators\n","- https://www.kaggle.com/hbfree/covid19formattedweatherjan22march24\n","- https://github.com/tyz910/sberbank-covid19/blob/master/quarantine_dates.csv"]},{"cell_type":"code","metadata":{"id":"0G9ENEpLtZDv","colab_type":"code","colab":{}},"source":["debug = False\n","last_test_day = '2020/04/30' if debug else '2020/12/31'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gUaIufwXpiI1","colab_type":"text"},"source":["# Imports and updates\n"]},{"cell_type":"code","metadata":{"id":"U9Ucn4Wp74z-","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","from IPython.display import clear_output\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/kaggle/covid_forecast')\n","clear_output()\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaBX5BpzxleI","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n","from sklearn.linear_model import Ridge\n","from scipy.optimize import curve_fit\n","import json\n","import lightgbm as lgb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"btPtDIBflPIb","colab_type":"code","colab":{}},"source":["# make upgrade daily\n","update = False\n","if update:\n","    !rm -rf COVID-19\n","    !rm -rf COVID-19-web\n","    !git clone https://github.com/CSSEGISandData/COVID-19.git\n","    !git clone --single-branch --branch web-data https://github.com/CSSEGISandData/COVID-19.git COVID-19-web"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VsdKlRs13qJ","colab_type":"code","colab":{}},"source":["def male(y, yhat):\n","    err = np.mean(np.absolute(np.log10((yhat + 1) / (y + 1))))\n","    return ('male', err, False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6JdST9MkbvE9","colab_type":"text"},"source":["# Open and merge datasets, look at data"]},{"cell_type":"markdown","metadata":{"id":"eUKM8S8RaJo4","colab_type":"text"},"source":["### World development index to rate country situation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3259eOCoiTJ8","colab":{}},"source":["wdi_features = [\n","    'Country Code',\n","    \"Air transport, passengers carried\",\n","    \"Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)\",\n","    \"Cause of death, by non-communicable diseases (% of total)\",\n","    \"Current health expenditure per capita, PPP (current international $)\",\n","    \"Death rate, crude (per 1,000 people)\",\n","    \"Diabetes prevalence (% of population ages 20 to 79)\",\n","    \"GDP per capita, PPP (current international $)\",\n","    \"Hospital beds (per 1,000 people)\",\n","    \"Incidence of tuberculosis (per 100,000 people)\",\n","    \"International migrant stock, total\",\n","    \"International tourism, number of arrivals\",\n","    \"International tourism, number of departures\",\n","    \"Labor force participation rate, total (% of total population ages 15+) (modeled ILO estimate)\",\n","    \"Life expectancy at birth, total (years)\",\n","    \"Mortality from CVD, cancer, diabetes or CRD between exact ages 30 and 70 (%)\",\n","    \"Mortality rate attributed to household and ambient air pollution, age-standardized (per 100,000 population)\",\n","    \"Mortality rate attributed to unsafe water, unsafe sanitation and lack of hygiene (per 100,000 population)\",\n","    \"Mortality rate, adult, female (per 1,000 female adults)\",\n","    \"Mortality rate, adult, male (per 1,000 male adults)\",\n","    \"Number of people spending more than 10% of household consumption or income on out-of-pocket health care expenditure\",\n","    \"Number of people spending more than 25% of household consumption or income on out-of-pocket health care expenditure\",\n","    \"Out-of-pocket expenditure (% of current health expenditure)\",\n","    \"People using at least basic sanitation services (% of population)\",\n","    \"People using safely managed sanitation services (% of population)\",\n","    \"People with basic handwashing facilities including soap and water (% of population)\",\n","    \"PM2.5 air pollution, population exposed to levels exceeding WHO guideline value (% of total)\",\n","    \"Population ages 15-64 (% of total)\",\n","    \"Population ages 65 and above (% of total)\",\n","    \"Population density (people per sq. km of land area)\",\n","    \"Population in the largest city (% of urban population)\",\n","    \"Population in urban agglomerations of more than 1 million (% of total population)\",\n","    \"Population, total\",\n","    \"Poverty headcount ratio at $3.20 a day (2011 PPP) (% of population)\",\n","    \"Prevalence of HIV, total (% of population ages 15-49)\",\n","    \"Smoking prevalence, females (% of adults)\",\n","    \"Smoking prevalence, males (% of adults)\",\n","    \"Survival to age 65, female (% of cohort)\",\n","    \"Survival to age 65, male (% of cohort)\",\n","    \"Trade (% of GDP)\",\n","    \"Tuberculosis case detection rate (%, all forms)\",\n","    \"Tuberculosis treatment success rate (% of new cases)\",\n","    \"Urban population (% of total)\"\n","]\n","\n","def read_wdi(fp='wdi-csv-zip-57-mb-/WDIData.csv'):\n","    wdi = pd.read_csv(fp)\n","    wdi = wdi.pivot(index='Country Code', columns='Indicator Name', values='2016').reset_index()[wdi_features]\n","    return wdi\n","\n","wdi = read_wdi()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9mRGi3KoiUaO","colab_type":"text"},"source":["### Dataset with quarantine, medianage, beds in hospital"]},{"cell_type":"code","metadata":{"id":"RVExEO7qf4jx","colab_type":"code","colab":{}},"source":["actions_taken = pd.read_csv('covid_dataset.csv').replace({-999: np.nan})\n","\n","'''for this criterias max value represents the situation better'''\n","maxes = actions_taken.groupby('Country/Region')[['quarantine', 'schools', 'restrictions', 'tests', 'testpop']].max().reset_index()\n","'''for this criterias mean value represents the situation better'''\n","means = actions_taken.groupby('Country/Region')[['temperature', 'hospibed', 'medianage']].mean().reset_index()\n","\n","actions_taken = pd.merge(maxes, means, on='Country/Region')\n","\n","at_features = actions_taken.columns[1:].to_list()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NX17V1HLoGSH","colab_type":"text"},"source":["### Additional info about countries"]},{"cell_type":"code","metadata":{"id":"AaekYNTeU3ec","colab_type":"code","colab":{}},"source":["add_countries_info = pd.read_csv('countries of the world.csv')\n","add_countries_features = ['Country', 'Region', 'Net migration', 'Infant mortality (per 1000 births)', 'GDP ($ per capita)']\n","add_countries_info = add_countries_info[add_countries_features]\n","add_countries_info['Country'] = add_countries_info['Country'].str.strip()\n","for f in add_countries_features[2:-1]:\n","    add_countries_info[f] = add_countries_info[f].str.replace(',', '.').astype(float)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"474eFhZp0RwX","colab_type":"text"},"source":["### Quarantine info"]},{"cell_type":"code","metadata":{"id":"r_8foxA70Umw","colab_type":"code","colab":{}},"source":["quar = pd.read_csv('quarantine_dates.csv')\n","quar.replace({'United States': 'US'}, inplace=True)\n","quar['Start date'] = pd.to_datetime(quar['Start date'])\n","quar['End date'] = pd.to_datetime(quar['End date'])\n","quar = quar.drop_duplicates(['Country'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfggocisivv5","colab_type":"text"},"source":["### Datasets provided by some university\n"]},{"cell_type":"code","metadata":{"id":"Cm1ZPberqlPJ","colab_type":"code","colab":{}},"source":["def merge_provinces(df):\n","    days = df.columns[4:]\n","    grouped = df.groupby('Country/Region')\n","    new_df = pd.concat([grouped[['Lat', 'Long']].mean(), grouped[days].sum()], axis=1)\n","    return new_df.reset_index()\n","\n","def add_test(df):\n","    # make test part filled with nans\n","    last_train_day = df.columns[-1]\n","\n","    first_test_day = pd.to_datetime(last_train_day) + pd.Timedelta(days=1)\n","    t_cols = pd.date_range(first_test_day, pd.to_datetime(last_test_day)).to_series().dt.strftime('%m/%d/%Y')\n","    test = pd.DataFrame(np.nan, index=df.index, columns=t_cols)\n","    test['Country/Region'] = df['Country/Region']\n","\n","    return pd.merge(df, test, on='Country/Region')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzt7ZfzPp2r1","colab_type":"code","colab":{}},"source":["# read given data\n","ss = pd.read_csv('sample_submission_dDoEbyO.csv')\n","countries = pd.read_csv('countries.csv').dropna(subset=['iso_alpha2'])\n","confirmed = pd.read_csv('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv').pipe(merge_provinces)\n","dead = pd.read_csv('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv').pipe(merge_provinces)\n","recovered = pd.read_csv('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv').pipe(merge_provinces)\n","\n","# use it later for train test split\n","last_train_day = pd.to_datetime('2020/04/12')\n","# last_train_day = pd.to_datetime(confirmed.columns[-1]) + pd.Timedelta(days=1)\n","\n","# add test\n","confirmed = confirmed.pipe(add_test)\n","recovered = recovered.pipe(add_test)\n","dead = dead.pipe(add_test)\n","\n","\n","# merge given countries info with obtained one\n","countries = pd.merge(countries, wdi, how='left', left_on='iso_alpha3', right_on='Country Code')\n","countries = pd.merge(countries, actions_taken, how='left', left_on='ccse_name', right_on='Country/Region')\n","countries = pd.merge(countries, add_countries_info, how='left', left_on='ccse_name', right_on='Country')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9vxG6qeBWU4","colab_type":"code","colab":{}},"source":["latest_data = pd.read_csv('COVID-19-web/data/cases_country.csv')\n","d = pd.to_datetime(latest_data['Last_Update']).max()\n","d = d.strftime('%m/%d/%Y')\n","\n","latest_data = latest_data.set_index('Country_Region').loc[confirmed['Country/Region']].reset_index()\n","\n","confirmed[d] = latest_data['Confirmed']\n","dead[d] = latest_data['Deaths']\n","recovered[d] = latest_data['Recovered']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZzJksfuoqTbD","colab":{}},"source":["len(set(list(actions_taken['Country/Region'])).intersection(set(list(countries['ccse_name']))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uwWJOxfBqTRU","colab":{}},"source":["len(set(list(add_countries_info['Country'])).intersection(set(list(countries['ccse_name']))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lE1eHUceqbqC","colab_type":"code","colab":{}},"source":["len(set(list(wdi['Country Code'])).intersection(set(list(countries['iso_alpha3']))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hv32ixMC0-YZ","colab_type":"code","colab":{}},"source":["len(set(list(quar['Country'])).intersection(set(list(countries['Country/Region']))))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aGiGdHj1X06d","colab_type":"text"},"source":["# Now you see?\n"]},{"cell_type":"code","metadata":{"id":"afoCYV6J0IVL","colab_type":"code","colab":{}},"source":["def plot_ts(x, x_axis=None, labels=None):\n","    # plot time series\n","    if labels is None:\n","        labels = list(range(len(x)))\n","    fig = px.line()\n","    for i in range(len(x)):\n","        fig.add_trace(go.Scatter(\n","                y=x[i],\n","                x=x_axis,\n","                name=f\"{labels[i]}\",\n","                opacity=0.8))\n","    fig.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLs-1aEt0JcC","colab_type":"code","colab":{}},"source":["plot_ts(confirmed[confirmed.columns[4:]].values, x_axis=confirmed.columns[4:], labels=confirmed['Country/Region'].values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_ehAL0FG5rE","colab_type":"code","colab":{}},"source":["plot_ts(dead[dead.columns[4:]].values, x_axis=dead.columns[4:], labels=dead['Country/Region'].values)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pp_NkuFYX7r2","colab_type":"text"},"source":["# Feature engeneering"]},{"cell_type":"markdown","metadata":{"id":"tcdZe0KZKLuI","colab_type":"text"},"source":["### Quarantine and country features\n"]},{"cell_type":"code","metadata":{"id":"PoAu4EP8Ux0s","colab_type":"code","colab":{}},"source":["num_features = []\n","cat_features = []\n","targets = ['confirmed', 'dead', 'recovered']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXIOrmiVuAhq","colab_type":"code","colab":{}},"source":["# melt and merge everyting\n","def melt(df, value_name='None'):\n","    # to not to write it 3 times\n","    melted = df.melt(id_vars=['Country/Region', 'Lat', 'Long'], var_name='date', value_name=value_name)\n","    melted['date'] = pd.to_datetime(melted['date'])\n","    return melted\n","\n","# join recovered, dead and confirmed into single dataset\n","melted = pd.merge(melt(dead, 'dead'), melt(confirmed, 'confirmed'), on=['Country/Region', 'date'])\n","melted = pd.merge(melted, melt(recovered, 'recovered'), on=['Country/Region', 'date'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IvcNIeqRZff6","colab":{}},"source":["melted = pd.merge(melted, quar, how='left', left_on='Country/Region', right_on='Country')\n","\n","# add quarantine features\n","melted['days_since_quar_start'] = melted['date'] - melted['Start date']\n","\n","# make delta float and remove negative deltas\n","melted['days_since_quar_start'] = melted['days_since_quar_start'] / np.timedelta64(1, 'D')\n","melted.loc[melted['days_since_quar_start'] < 0, 'days_since_quar_start'] = np.nan\n","\n","melted.rename({'Level': 'quar_type'}, axis=1, inplace=True)\n","\n","num_features += ['days_since_quar_start']\n","cat_features += ['quar_type']\n","\n","# add countries features\n","data = pd.merge(melted, countries, left_on='Country/Region', right_on='ccse_name', how='left')\n","data.rename({'Country/Region_x': 'Country/Region'}, axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQS-DvTPXbS_","colab_type":"code","colab":{}},"source":["for t in targets:\n","    data[t] = np.maximum(0, data[t])\n","\n","# important note: we are predicting delta, not cumulative sum\n","data.loc[:, targets] = data[targets] - data.groupby('Country/Region')[targets].shift(1)\n","\n","for t in targets:\n","    data[t] = np.maximum(0, data[t])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFM53SQ6LYAK","colab_type":"text"},"source":["### Time based features"]},{"cell_type":"code","metadata":{"id":"xgLyLwmhMp4_","colab_type":"code","colab":{}},"source":["# if our max shift/rolling is  7 set days to 7\n","# used to not to recalculate all date statistics when predicting recursively\n","max_shift = 8\n","max_shift_delta = pd.Timedelta(days=max_shift)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4uX-52yRO8x","colab_type":"code","colab":{}},"source":["def ridge_features(y):\n","    # returns Ridge params and predictions a week ahead\n","    pred_day = 8\n","\n","    if (y.isna().any()) or (y == 0).all():\n","        return pd.Series(np.zeros((3,)), index=['ridge_bias', 'ridge_coef', 'ridge_pred'])        \n","    x = np.arange(1, len(y) + 1).reshape(len(y), -1)\n","    y = y[::-1]\n","    r = Ridge()\n","    r.fit(x, y)\n","    pred = r.predict([[pred_day]])[0]\n","    return pd.Series([r.coef_[0], r.intercept_, pred], index=['ridge_bias', 'ridge_coef', 'ridge_pred'])\n","\n","def poly_features(y):\n","    # fit polynomial to data, to better see growth\n","    # returns poly coeffs and pred\n","    deg = 3  # polynomial up to deg order\n","    pred_day = 8 # day we make predictions for\n","    cnames = [f'poly_{i}' for i in range(deg + 1)] + ['poly_pred']\n","    if (y.isna().any()) or (y == 0).all():\n","        return pd.Series(np.zeros((len(cnames),)), index=cnames)\n","    x = np.arange(1, len(y) + 1)\n","    y = y[::-1]\n","    params = np.polyfit(x, y, deg)[::-1]\n","    pred = np.polyval(params[::-1], [pred_day])\n","    return pd.Series(np.append(params, pred), index=cnames)\n","\n","def add_time_features(data):\n","    num_features = []\n","    cat_features = []\n","    \n","    # add lag features\n","    lags = [1, 2, 3, 4, 5, 6, 7]\n","    for lag in lags:\n","        lag_features = data.groupby('Country/Region')[['confirmed', 'dead', 'recovered']].shift(lag)\n","        lag_features.columns = [f'{col}_lag_{lag}' for col in lag_features.columns]\n","        num_features += lag_features.columns.to_list()\n","        data.drop(lag_features.columns, axis=1, inplace=True, errors='ignore')\n","        data = pd.concat([data, lag_features], axis=1)\n","\n","    # rolling statistics\n","    window = 7\n","    rollings = data.groupby('Country/Region')[['confirmed', 'dead', 'recovered']].shift(1).rolling(window).agg(['mean', 'std', 'max', 'min'])\n","    rollings.columns = ['rolling_' + '_'.join(i) for i in rollings.columns]\n","    num_features += rollings.columns.to_list()\n","    data.drop(rollings.columns, axis=1, inplace=True, errors='ignore')\n","    data = pd.concat([data, rollings], axis=1)\n","\n","    # max target delta expanding\n","    for t in targets:\n","        data[t + '_expanding_max'] = data.groupby('Country/Region')[t].transform(lambda x: x.shift(1).expanding().max())\n","        num_features += [t + '_expanding_max']\n","\n","    #  max_confirmed - lag1_confirmed, max_confirmed - lag2_confirmed\n","\n","    lag_minus_max_features = ['lag1_minus_max', 'lag2_minus_max', 'lag3_minus_max']\n","    lag_minus_max = [1, 2, 3]\n","    for l, col_name in zip(lag_minus_max, lag_minus_max_features):\n","        data[col_name] = data['confirmed_expanding_max'] - data[f'confirmed_lag_{l}']\n","    num_features += lag_minus_max_features\n","\n","    if True:\n","        # ridge regression and polynomial on lags for confirmed, recovered and dead\n","        for t in ['confirmed_', 'recovered_', 'dead_']:\n","            t_lags = data.columns[data.columns.str.contains(t + 'lag_')]\n","            rfs = data[t_lags].apply(ridge_features, axis=1, result_type='expand')\n","            rfs.columns = [t + i for i in rfs.columns]\n","            data.drop(rfs.columns, axis=1, inplace=True, errors='ignore')\n","            data = pd.concat([data, rfs], axis=1)\n","            num_features += rfs.columns.to_list()\n","\n","            pfs = data[t_lags].apply(poly_features, axis=1, result_type='expand')\n","            pfs.columns = [t + i for i in pfs.columns]\n","            data.drop(pfs.columns, axis=1, inplace=True, errors='ignore')\n","            data = pd.concat([data, pfs], axis=1)\n","            num_features += pfs.columns.to_list()\n","\n","    return data, num_features, cat_features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1MdsSJPNvjY","colab_type":"code","colab":{}},"source":["data, time_num_features, time_cat_features = add_time_features(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5yquKt8cW6Y","colab_type":"code","colab":{}},"source":["num_features += wdi_features[1:]  # first is country code\n","num_features += ['Net migration', 'Infant mortality (per 1000 births)', 'GDP ($ per capita)']  # add info features\n","cat_features += ['Region']\n","num_features += at_features  # actions taken features\n","num_features += time_num_features\n","cat_features += time_cat_features\n","\n","num_features = list(set(num_features))\n","cat_features = list(set(cat_features))\n","\n","features = num_features + cat_features\n","len(features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"usiDaQAbnzOR","colab_type":"code","colab":{}},"source":["# early days don't contain much info and we don't need nan targets in train\n","data = data[\n","    data['date'] >= '02/01/2020'\n","]\n","data\n","# fill nans and encode cat features\n","data.loc[:, cat_features] = data[cat_features].fillna('None')\n","data.loc[:, num_features] = data.loc[:, num_features].fillna(0)\n","\n","for cat_f in cat_features:\n","    cat_en = LabelEncoder()\n","    data[cat_f] = cat_en.fit_transform(data[cat_f])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZXONwt8my1k","colab_type":"text"},"source":["# Let's try to fit something"]},{"cell_type":"code","metadata":{"id":"e_PQns7s5Rzz","colab_type":"code","colab":{}},"source":["print(last_train_day)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIwq7p42avP4","colab_type":"code","colab":{}},"source":["def fit_lgb(train):\n","    # features are finetuned in a separate kernel\n","    booster_params = {\n","        'confirmed': {\n","            'objective': 'poisson', 'boosting_type': 'gbdt', 'n_jobs': -1, 'seed': 2, 'num_iterations': 1500, 'learning_rate': 0.03, 'num_leaves': 127, \n","            'min_data_in_leaf': 35, 'min_gain_to_split': 0.1, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 1.0, 'lambda_l2': 0.0\n","        }, \n","        'dead': {\n","            'objective': 'poisson', 'boosting_type': 'gbdt', 'n_jobs': -1, 'seed': 2, 'num_iterations': 1500, 'learning_rate': 0.03, 'num_leaves': 127, \n","            'min_data_in_leaf': 25, 'min_gain_to_split': 0.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 1.0, 'lambda_l2': 0.05\n","        }, \n","        'recovered': {\n","            'objective': 'regression', 'boosting_type': 'gbdt', 'n_jobs': -1, 'seed': 2, 'num_iterations': 1500, 'learning_rate': 0.01, 'num_leaves': 15, \n","            'min_data_in_leaf': 35, 'min_gain_to_split': 0.1, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 0.8, 'lambda_l2': 0.0\n","        }\n","    }\n","    boosters = {}\n","    X_train = train[features]\n","    for t in targets:\n","        y_train = train[t]\n","        model = lgb.LGBMRegressor(**booster_params[t])\n","        print(f\"Fitting {t}'s model\")\n","        model.fit(\n","            X_train, y_train,\n","            eval_metric=male,\n","            eval_set=[(X_train, y_train)],\n","            verbose=100,\n","            categorical_feature=cat_features\n","        )\n","        print()\n","        boosters[t] = model\n","    return boosters"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SpifAtQk6E9","colab_type":"code","colab":{}},"source":["def run_lgb(models, test):\n","    preds = pd.DataFrame()\n","    for key in models.keys():\n","        pred = np.maximum(0, models[key].predict(test[features]))\n","        pred = np.round(pred).astype('int')\n","        preds[key] = pred\n","    return preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzDQPu1UWGNG","colab_type":"code","colab":{}},"source":["def fit_predict_recursively(data, train_last_day):\n","    data = data.copy()\n","    train = data[data['date'] <= train_last_day]\n","    test = data[data['date'] > train_last_day]\n","\n","    models = fit_lgb(train)\n","    for i in range(1, int((test['date'].max() - train_last_day).days + 1)):\n","        pred_day = train_last_day + pd.Timedelta(days=i)\n","        print(pred_day)\n","        # recalculate time_features for pred_day\n","        recalc_window = (data['date'] >= pred_day - max_shift_delta) & (data['date'] <= pred_day)\n","        recalced = add_time_features(data.loc[recalc_window])[0]\n","        data.loc[data['date'] == pred_day, :] = recalced.loc[recalced['date'] == pred_day, :]\n","        xt = data[data['date'] == pred_day]\n","        data.loc[data['date'] == pred_day, targets] = run_lgb(models, xt).values\n","\n","    return data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nt4ZaEviC9vO","colab_type":"code","colab":{}},"source":["def crossval(data, h) -> (float, float):\n","    val_data = data[data['date'] <= last_train_day]\n","    val_last_train_day = last_train_day - pd.Timedelta(days=h)\n","\n","    val_preds = fit_predict_recursively(val_data, val_last_train_day)\n","    val_preds = val_preds[val_preds['date'] > val_last_train_day]\n","    val_real = val_data[val_data['date'] > val_last_train_day]\n","    return male(val_real['confirmed'], val_preds['confirmed'])[1], male(val_real['dead'], val_preds['dead'])[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMY7O57pDA61","colab_type":"code","colab":{}},"source":["crossval(data, 7)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"biGYW4rB8O2R","colab_type":"text"},"source":["# Visualize validationpredictions\n"]},{"cell_type":"code","metadata":{"id":"F_oqFTKMC_mD","colab_type":"code","colab":{}},"source":["pdata = fit_predict_recursively(data, last_train_day)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Tei0_m78ZP2","colab_type":"code","colab":{}},"source":["def pivot_cum(df, target):\n","    pdf = df.pivot('Country/Region', 'date', target)\n","    pdf.columns = pdf.columns.to_series().dt.strftime('%m/%d/%Y')\n","    pdf = pdf.cumsum(axis=1)\n","    return pdf.reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhZO6RVduffl","colab_type":"code","colab":{}},"source":["# stands for pivot cumulated\n","confirmed_pred = pivot_cum(pdata, 'confirmed')\n","confirmed_pred = confirmed_pred.sort_values(by=confirmed_pred.columns[-1], ascending=False)\n","\n","dead_pred = pivot_cum(pdata, 'dead')\n","dead_pred = dead_pred.sort_values(by=dead_pred.columns[-1], ascending=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjiBWTTj6LHk","colab_type":"code","colab":{}},"source":["plot_ts(confirmed_pred.iloc[:, 1:].values, x_axis=confirmed_pred.iloc[:, 1:].columns, labels=confirmed_pred['Country/Region'].values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCCrv4UhvURD","colab_type":"code","colab":{}},"source":["plot_ts(dead_pred.iloc[:, 1:].values, x_axis=dead_pred.iloc[:, 1:].columns, labels=dead_pred['Country/Region'].values)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pfyU5D70dFm","colab_type":"text"},"source":["# Write submission"]},{"cell_type":"code","metadata":{"id":"jMLwm9L-oHKC","colab_type":"code","colab":{}},"source":["def to_csv(conf_pred, dead_pred, fp='subs/covid_preds.csv'):\n","    # process and write to csv\n","    cols_order = ss.columns\n","    conf_pred = pd.merge(conf_pred, countries[['ccse_name', 'iso_alpha3']], left_on='Country/Region', right_on='ccse_name').drop(['Country/Region', 'ccse_name'], axis=1).melt('iso_alpha3', var_name='date', value_name='confirmed')\n","    dead_pred = pd.merge(dead_pred, countries[['ccse_name', 'iso_alpha3']], left_on='Country/Region', right_on='ccse_name').drop(['Country/Region', 'ccse_name'], axis=1).melt('iso_alpha3', var_name='date', value_name='dead')\n","\n","    mysub = pd.merge(conf_pred, dead_pred, on=['iso_alpha3', 'date'])\n","    mysub['date'] = pd.to_datetime(mysub['date'])\n","    mysub = mysub[mysub['date'] >= '2020-04-05']\n","    mysub['date'] = mysub['date'].dt.strftime('%Y-%m-%d')\n","    mysub = mysub.rename({'iso_alpha3': 'country'}, axis=1).reset_index(drop=True)\n","    mysub = pd.merge(ss, mysub, on=['date', 'country'], how='left')\n","    mysub.drop(['prediction_confirmed', 'prediction_deaths'], axis=1, inplace=True)\n","    mysub.rename({'confirmed': 'prediction_confirmed', 'dead': 'prediction_deaths'}, axis=1, inplace=True)\n","    mysub = mysub[cols_order]\n","    print(mysub.isna().sum().to_string())\n","    mysub['prediction_confirmed'] = mysub['prediction_confirmed'].fillna(18)\n","    mysub['prediction_deaths'] = mysub['prediction_deaths'].fillna(0)\n","    print(mysub.isna().sum().to_string())\n","    mysub['prediction_confirmed'] = mysub['prediction_confirmed'].astype(int)\n","    mysub['prediction_deaths'] = mysub['prediction_deaths'].astype(int)\n","\n","    mysub.to_csv(fp, index=False)\n","\n","to_csv(confirmed_pred, dead_pred, 'subs/latest_data.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnvGMGi_5IOq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"c299493b-3dba-4a1f-bd97-68735fb5167f","executionInfo":{"status":"ok","timestamp":1587785538585,"user_tz":-600,"elapsed":1770,"user":{"displayName":"Даниил Цимерман","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW801CjZAa4FtuOmLzD5v2cc1gUWuL8CGiGqcT=s64","userId":"00628076829980203964"}}},"source":["pd.read_csv('subs/latest_data.csv')"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>country</th>\n","      <th>prediction_confirmed</th>\n","      <th>prediction_deaths</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-04-05</td>\n","      <td>AFG</td>\n","      <td>349</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-04-06</td>\n","      <td>AFG</td>\n","      <td>367</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-04-07</td>\n","      <td>AFG</td>\n","      <td>423</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-04-08</td>\n","      <td>AFG</td>\n","      <td>444</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-04-09</td>\n","      <td>AFG</td>\n","      <td>484</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>45794</th>\n","      <td>2020-12-27</td>\n","      <td>ZWE</td>\n","      <td>14</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>45795</th>\n","      <td>2020-12-28</td>\n","      <td>ZWE</td>\n","      <td>14</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>45796</th>\n","      <td>2020-12-29</td>\n","      <td>ZWE</td>\n","      <td>14</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>45797</th>\n","      <td>2020-12-30</td>\n","      <td>ZWE</td>\n","      <td>14</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>45798</th>\n","      <td>2020-12-31</td>\n","      <td>ZWE</td>\n","      <td>14</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>45799 rows × 4 columns</p>\n","</div>"],"text/plain":["             date country  prediction_confirmed  prediction_deaths\n","0      2020-04-05     AFG                   349                  7\n","1      2020-04-06     AFG                   367                 11\n","2      2020-04-07     AFG                   423                 14\n","3      2020-04-08     AFG                   444                 14\n","4      2020-04-09     AFG                   484                 15\n","...           ...     ...                   ...                ...\n","45794  2020-12-27     ZWE                    14                  3\n","45795  2020-12-28     ZWE                    14                  3\n","45796  2020-12-29     ZWE                    14                  3\n","45797  2020-12-30     ZWE                    14                  3\n","45798  2020-12-31     ZWE                    14                  3\n","\n","[45799 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]}]}